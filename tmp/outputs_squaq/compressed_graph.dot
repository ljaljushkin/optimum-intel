strict digraph  {
"0 /nncf_model_input_0";
"1 /nncf_model_input_1";
"2 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Embeddings[embeddings]/NNCFEmbedding[word_embeddings]/embedding_0";
"3 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Embeddings[embeddings]/NNCFEmbedding[position_embeddings]/embedding_0";
"4 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Embeddings[embeddings]/__add___0";
"5 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Embeddings[embeddings]/NNCFLayerNorm[LayerNorm]/layer_norm_0";
"6 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Embeddings[embeddings]/Dropout[dropout]/dropout_0";
"7 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"8 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/AsymmetricQuantizer/asymmetric_quantize_0";
"9 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/linear_0";
"10 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/view_0";
"11 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/transpose_0";
"12 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"13 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/AsymmetricQuantizer/asymmetric_quantize_0";
"14 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/linear_0";
"15 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/SymmetricQuantizer/symmetric_quantize_0";
"16 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/view_1";
"17 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/transpose_1";
"18 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"19 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/AsymmetricQuantizer/asymmetric_quantize_0";
"20 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/linear_0";
"21 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/view_2";
"22 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/transpose_2";
"23 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/__truediv___0";
"24 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/SymmetricQuantizer/symmetric_quantize_0";
"25 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/transpose_3";
"26 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/matmul_0";
"27 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/__eq___0";
"28 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/view_3";
"29 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/expand_as_0";
"30 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/masked_fill_0";
"31 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/softmax_0";
"32 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/Dropout[dropout]/dropout_0";
"33 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/matmul_1";
"34 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/AsymmetricQuantizer/asymmetric_quantize_0";
"35 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/transpose_4";
"36 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/contiguous_0";
"37 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/view_4";
"38 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/NNCFLinear[out_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"39 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/NNCFLinear[out_lin]/linear_0";
"40 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/__add___0";
"41 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/NNCFLayerNorm[sa_layer_norm]/layer_norm_0";
"42 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/FFN[ffn]/NNCFLinear[lin1]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"43 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/FFN[ffn]/NNCFLinear[lin1]/AsymmetricQuantizer/asymmetric_quantize_0";
"44 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/FFN[ffn]/NNCFLinear[lin1]/linear_0";
"45 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/FFN[ffn]/GELUActivation[activation]/gelu_0";
"46 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/FFN[ffn]/GELUActivation[activation]/AsymmetricQuantizer/asymmetric_quantize_0";
"47 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/FFN[ffn]/NNCFLinear[lin2]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"48 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/FFN[ffn]/NNCFLinear[lin2]/linear_0";
"49 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/FFN[ffn]/Dropout[dropout]/dropout_0";
"50 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/__add___1";
"51 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/NNCFLayerNorm[output_layer_norm]/layer_norm_0";
"52 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"53 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/AsymmetricQuantizer/asymmetric_quantize_0";
"54 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/linear_0";
"55 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/view_0";
"56 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/transpose_0";
"57 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"58 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/AsymmetricQuantizer/asymmetric_quantize_0";
"59 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/linear_0";
"60 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/SymmetricQuantizer/symmetric_quantize_0";
"61 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/view_1";
"62 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/transpose_1";
"63 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"64 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/AsymmetricQuantizer/asymmetric_quantize_0";
"65 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/linear_0";
"66 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/view_2";
"67 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/transpose_2";
"68 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/__truediv___0";
"69 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/SymmetricQuantizer/symmetric_quantize_0";
"70 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/transpose_3";
"71 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/matmul_0";
"72 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/__eq___0";
"73 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/view_3";
"74 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/expand_as_0";
"75 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/masked_fill_0";
"76 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/softmax_0";
"77 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/Dropout[dropout]/dropout_0";
"78 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/matmul_1";
"79 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/AsymmetricQuantizer/asymmetric_quantize_0";
"80 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/transpose_4";
"81 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/contiguous_0";
"82 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/view_4";
"83 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/NNCFLinear[out_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"84 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/NNCFLinear[out_lin]/linear_0";
"85 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/__add___0";
"86 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/NNCFLayerNorm[sa_layer_norm]/layer_norm_0";
"87 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/FFN[ffn]/NNCFLinear[lin1]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"88 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/FFN[ffn]/NNCFLinear[lin1]/AsymmetricQuantizer/asymmetric_quantize_0";
"89 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/FFN[ffn]/NNCFLinear[lin1]/linear_0";
"90 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/FFN[ffn]/GELUActivation[activation]/gelu_0";
"91 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/FFN[ffn]/GELUActivation[activation]/AsymmetricQuantizer/asymmetric_quantize_0";
"92 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/FFN[ffn]/NNCFLinear[lin2]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"93 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/FFN[ffn]/NNCFLinear[lin2]/linear_0";
"94 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/FFN[ffn]/Dropout[dropout]/dropout_0";
"95 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/__add___1";
"96 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/NNCFLayerNorm[output_layer_norm]/layer_norm_0";
"97 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"98 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/AsymmetricQuantizer/asymmetric_quantize_0";
"99 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/linear_0";
"100 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/view_0";
"101 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/transpose_0";
"102 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"103 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/AsymmetricQuantizer/asymmetric_quantize_0";
"104 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/linear_0";
"105 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/SymmetricQuantizer/symmetric_quantize_0";
"106 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/view_1";
"107 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/transpose_1";
"108 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"109 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/AsymmetricQuantizer/asymmetric_quantize_0";
"110 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/linear_0";
"111 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/view_2";
"112 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/transpose_2";
"113 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/__truediv___0";
"114 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/SymmetricQuantizer/symmetric_quantize_0";
"115 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/transpose_3";
"116 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/matmul_0";
"117 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/__eq___0";
"118 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/view_3";
"119 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/expand_as_0";
"120 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/masked_fill_0";
"121 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/softmax_0";
"122 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/Dropout[dropout]/dropout_0";
"123 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/matmul_1";
"124 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/AsymmetricQuantizer/asymmetric_quantize_0";
"125 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/transpose_4";
"126 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/contiguous_0";
"127 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/view_4";
"128 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/NNCFLinear[out_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"129 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/NNCFLinear[out_lin]/linear_0";
"130 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/__add___0";
"131 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/NNCFLayerNorm[sa_layer_norm]/layer_norm_0";
"132 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/FFN[ffn]/NNCFLinear[lin1]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"133 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/FFN[ffn]/NNCFLinear[lin1]/AsymmetricQuantizer/asymmetric_quantize_0";
"134 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/FFN[ffn]/NNCFLinear[lin1]/linear_0";
"135 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/FFN[ffn]/GELUActivation[activation]/gelu_0";
"136 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/FFN[ffn]/GELUActivation[activation]/AsymmetricQuantizer/asymmetric_quantize_0";
"137 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/FFN[ffn]/NNCFLinear[lin2]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"138 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/FFN[ffn]/NNCFLinear[lin2]/linear_0";
"139 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/FFN[ffn]/Dropout[dropout]/dropout_0";
"140 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/__add___1";
"141 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/NNCFLayerNorm[output_layer_norm]/layer_norm_0";
"142 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"143 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/AsymmetricQuantizer/asymmetric_quantize_0";
"144 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/linear_0";
"145 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/view_0";
"146 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/transpose_0";
"147 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"148 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/AsymmetricQuantizer/asymmetric_quantize_0";
"149 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/linear_0";
"150 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/SymmetricQuantizer/symmetric_quantize_0";
"151 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/view_1";
"152 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/transpose_1";
"153 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"154 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/AsymmetricQuantizer/asymmetric_quantize_0";
"155 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/linear_0";
"156 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/view_2";
"157 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/transpose_2";
"158 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/__truediv___0";
"159 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/SymmetricQuantizer/symmetric_quantize_0";
"160 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/transpose_3";
"161 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/matmul_0";
"162 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/__eq___0";
"163 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/view_3";
"164 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/expand_as_0";
"165 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/masked_fill_0";
"166 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/softmax_0";
"167 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/Dropout[dropout]/dropout_0";
"168 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/matmul_1";
"169 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/AsymmetricQuantizer/asymmetric_quantize_0";
"170 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/transpose_4";
"171 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/contiguous_0";
"172 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/view_4";
"173 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/NNCFLinear[out_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"174 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/NNCFLinear[out_lin]/linear_0";
"175 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/__add___0";
"176 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/NNCFLayerNorm[sa_layer_norm]/layer_norm_0";
"177 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/FFN[ffn]/NNCFLinear[lin1]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"178 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/FFN[ffn]/NNCFLinear[lin1]/AsymmetricQuantizer/asymmetric_quantize_0";
"179 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/FFN[ffn]/NNCFLinear[lin1]/linear_0";
"180 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/FFN[ffn]/GELUActivation[activation]/gelu_0";
"181 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/FFN[ffn]/GELUActivation[activation]/AsymmetricQuantizer/asymmetric_quantize_0";
"182 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/FFN[ffn]/NNCFLinear[lin2]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"183 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/FFN[ffn]/NNCFLinear[lin2]/linear_0";
"184 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/FFN[ffn]/Dropout[dropout]/dropout_0";
"185 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/__add___1";
"186 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/NNCFLayerNorm[output_layer_norm]/layer_norm_0";
"187 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"188 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/AsymmetricQuantizer/asymmetric_quantize_0";
"189 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/linear_0";
"190 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/view_0";
"191 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/transpose_0";
"192 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"193 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/AsymmetricQuantizer/asymmetric_quantize_0";
"194 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/linear_0";
"195 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/SymmetricQuantizer/symmetric_quantize_0";
"196 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/view_1";
"197 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/transpose_1";
"198 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"199 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/AsymmetricQuantizer/asymmetric_quantize_0";
"200 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/linear_0";
"201 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/view_2";
"202 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/transpose_2";
"203 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/__truediv___0";
"204 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/SymmetricQuantizer/symmetric_quantize_0";
"205 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/transpose_3";
"206 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/matmul_0";
"207 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/__eq___0";
"208 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/view_3";
"209 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/expand_as_0";
"210 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/masked_fill_0";
"211 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/softmax_0";
"212 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/Dropout[dropout]/dropout_0";
"213 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/matmul_1";
"214 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/AsymmetricQuantizer/asymmetric_quantize_0";
"215 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/transpose_4";
"216 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/contiguous_0";
"217 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/view_4";
"218 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/NNCFLinear[out_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"219 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/NNCFLinear[out_lin]/linear_0";
"220 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/__add___0";
"221 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/NNCFLayerNorm[sa_layer_norm]/layer_norm_0";
"222 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/FFN[ffn]/NNCFLinear[lin1]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"223 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/FFN[ffn]/NNCFLinear[lin1]/AsymmetricQuantizer/asymmetric_quantize_0";
"224 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/FFN[ffn]/NNCFLinear[lin1]/linear_0";
"225 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/FFN[ffn]/GELUActivation[activation]/gelu_0";
"226 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/FFN[ffn]/GELUActivation[activation]/AsymmetricQuantizer/asymmetric_quantize_0";
"227 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/FFN[ffn]/NNCFLinear[lin2]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"228 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/FFN[ffn]/NNCFLinear[lin2]/linear_0";
"229 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/FFN[ffn]/Dropout[dropout]/dropout_0";
"230 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/__add___1";
"231 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/NNCFLayerNorm[output_layer_norm]/layer_norm_0";
"232 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"233 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/AsymmetricQuantizer/asymmetric_quantize_0";
"234 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/linear_0";
"235 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/view_0";
"236 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/transpose_0";
"237 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"238 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/AsymmetricQuantizer/asymmetric_quantize_0";
"239 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/linear_0";
"240 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/SymmetricQuantizer/symmetric_quantize_0";
"241 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/view_1";
"242 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/transpose_1";
"243 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"244 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/AsymmetricQuantizer/asymmetric_quantize_0";
"245 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/linear_0";
"246 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/view_2";
"247 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/transpose_2";
"248 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/__truediv___0";
"249 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/SymmetricQuantizer/symmetric_quantize_0";
"250 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/transpose_3";
"251 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/matmul_0";
"252 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/__eq___0";
"253 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/view_3";
"254 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/expand_as_0";
"255 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/masked_fill_0";
"256 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/softmax_0";
"257 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/Dropout[dropout]/dropout_0";
"258 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/matmul_1";
"259 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/AsymmetricQuantizer/asymmetric_quantize_0";
"260 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/transpose_4";
"261 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/contiguous_0";
"262 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/view_4";
"263 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/NNCFLinear[out_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"264 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/NNCFLinear[out_lin]/linear_0";
"265 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/__add___0";
"266 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/NNCFLayerNorm[sa_layer_norm]/layer_norm_0";
"267 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/FFN[ffn]/NNCFLinear[lin1]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"268 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/FFN[ffn]/NNCFLinear[lin1]/AsymmetricQuantizer/asymmetric_quantize_0";
"269 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/FFN[ffn]/NNCFLinear[lin1]/linear_0";
"270 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/FFN[ffn]/GELUActivation[activation]/gelu_0";
"271 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/FFN[ffn]/GELUActivation[activation]/AsymmetricQuantizer/asymmetric_quantize_0";
"272 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/FFN[ffn]/NNCFLinear[lin2]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"273 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/FFN[ffn]/NNCFLinear[lin2]/linear_0";
"274 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/FFN[ffn]/Dropout[dropout]/dropout_0";
"275 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/__add___1";
"276 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/NNCFLayerNorm[output_layer_norm]/layer_norm_0";
"277 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/NNCFLayerNorm[output_layer_norm]/AsymmetricQuantizer/asymmetric_quantize_0";
"278 DistilBertForQuestionAnswering/Dropout[dropout]/dropout_0";
"279 DistilBertForQuestionAnswering/NNCFLinear[qa_outputs]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0";
"280 DistilBertForQuestionAnswering/NNCFLinear[qa_outputs]/linear_0";
"281 DistilBertForQuestionAnswering/split_0";
"282 DistilBertForQuestionAnswering/squeeze_0";
"283 DistilBertForQuestionAnswering/contiguous_0";
"284 DistilBertForQuestionAnswering/squeeze_1";
"285 DistilBertForQuestionAnswering/contiguous_1";
"286 /nncf_model_output_0";
"287 /nncf_model_output_1";
"0 /nncf_model_input_0" -> "2 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Embeddings[embeddings]/NNCFEmbedding[word_embeddings]/embedding_0"  [label="(8, 384) \n0 -> 0", style=dashed];
"1 /nncf_model_input_1" -> "27 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/__eq___0"  [label="(8, 384) \n0 -> 0", style=dashed];
"1 /nncf_model_input_1" -> "72 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/__eq___0"  [label="(8, 384) \n0 -> 0", style=dashed];
"1 /nncf_model_input_1" -> "117 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/__eq___0"  [label="(8, 384) \n0 -> 0", style=dashed];
"1 /nncf_model_input_1" -> "162 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/__eq___0"  [label="(8, 384) \n0 -> 0", style=dashed];
"1 /nncf_model_input_1" -> "207 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/__eq___0"  [label="(8, 384) \n0 -> 0", style=dashed];
"1 /nncf_model_input_1" -> "252 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/__eq___0"  [label="(8, 384) \n0 -> 0", style=dashed];
"2 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Embeddings[embeddings]/NNCFEmbedding[word_embeddings]/embedding_0" -> "4 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Embeddings[embeddings]/__add___0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"3 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Embeddings[embeddings]/NNCFEmbedding[position_embeddings]/embedding_0" -> "4 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Embeddings[embeddings]/__add___0"  [label="(1, 384, 768) \n0 -> 1", style=solid];
"4 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Embeddings[embeddings]/__add___0" -> "5 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Embeddings[embeddings]/NNCFLayerNorm[LayerNorm]/layer_norm_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"5 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Embeddings[embeddings]/NNCFLayerNorm[LayerNorm]/layer_norm_0" -> "6 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Embeddings[embeddings]/Dropout[dropout]/dropout_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"6 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Embeddings[embeddings]/Dropout[dropout]/dropout_0" -> "8 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"6 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Embeddings[embeddings]/Dropout[dropout]/dropout_0" -> "13 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"6 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Embeddings[embeddings]/Dropout[dropout]/dropout_0" -> "19 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"6 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Embeddings[embeddings]/Dropout[dropout]/dropout_0" -> "40 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/__add___0"  [label="(8, 384, 768) \n0 -> 1", style=solid];
"7 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "9 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/linear_0"  [label="(768, 768) \n0 -> 1", style=solid];
"8 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/AsymmetricQuantizer/asymmetric_quantize_0" -> "9 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/linear_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"9 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/linear_0" -> "10 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/view_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"10 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/view_0" -> "11 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/transpose_0"  [label="(8, 384, 12, 64) \n0 -> 0", style=solid];
"11 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/transpose_0" -> "23 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/__truediv___0"  [label="(8, 12, 384, 64) \n0 -> 0", style=solid];
"12 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "14 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/linear_0"  [label="(768, 768) \n0 -> 1", style=solid];
"13 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/AsymmetricQuantizer/asymmetric_quantize_0" -> "14 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/linear_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"14 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/linear_0" -> "15 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/SymmetricQuantizer/symmetric_quantize_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"15 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/SymmetricQuantizer/symmetric_quantize_0" -> "16 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/view_1"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"16 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/view_1" -> "17 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/transpose_1"  [label="(8, 384, 12, 64) \n0 -> 0", style=solid];
"17 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/transpose_1" -> "25 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/transpose_3"  [label="(8, 12, 384, 64) \n0 -> 0", style=solid];
"18 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "20 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/linear_0"  [label="(768, 768) \n0 -> 1", style=solid];
"19 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/AsymmetricQuantizer/asymmetric_quantize_0" -> "20 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/linear_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"20 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/linear_0" -> "21 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/view_2"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"21 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/view_2" -> "22 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/transpose_2"  [label="(8, 384, 12, 64) \n0 -> 0", style=solid];
"22 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/transpose_2" -> "33 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/matmul_1"  [label="(8, 12, 384, 64) \n0 -> 1", style=solid];
"23 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/__truediv___0" -> "24 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/SymmetricQuantizer/symmetric_quantize_0"  [label="(8, 12, 384, 64) \n0 -> 0", style=solid];
"24 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/SymmetricQuantizer/symmetric_quantize_0" -> "26 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/matmul_0"  [label="(8, 12, 384, 64) \n0 -> 0", style=solid];
"25 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/transpose_3" -> "26 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/matmul_0"  [label="(8, 12, 64, 384) \n0 -> 1", style=solid];
"26 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/matmul_0" -> "29 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/expand_as_0"  [label="(8, 12, 384, 384) \n0 -> 1", style=solid];
"26 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/matmul_0" -> "30 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/masked_fill_0"  [label="(8, 12, 384, 384) \n0 -> 0", style=solid];
"27 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/__eq___0" -> "28 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/view_3"  [label="(8, 384) \n0 -> 0", style=dashed];
"28 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/view_3" -> "29 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/expand_as_0"  [label="(8, 1, 1, 384) \n0 -> 0", style=dashed];
"29 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/expand_as_0" -> "30 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/masked_fill_0"  [label="(8, 12, 384, 384) \n0 -> 1", style=dashed];
"30 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/masked_fill_0" -> "31 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/softmax_0"  [label="(8, 12, 384, 384) \n0 -> 0", style=solid];
"31 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/softmax_0" -> "32 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/Dropout[dropout]/dropout_0"  [label="(8, 12, 384, 384) \n0 -> 0", style=solid];
"32 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/Dropout[dropout]/dropout_0" -> "33 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/matmul_1"  [label="(8, 12, 384, 384) \n0 -> 0", style=solid];
"33 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/matmul_1" -> "34 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(8, 12, 384, 64) \n0 -> 0", style=solid];
"34 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/AsymmetricQuantizer/asymmetric_quantize_0" -> "35 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/transpose_4"  [label="(8, 12, 384, 64) \n0 -> 0", style=solid];
"35 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/transpose_4" -> "36 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/contiguous_0"  [label="(8, 384, 12, 64) \n0 -> 0", style=solid];
"36 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/contiguous_0" -> "37 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/view_4"  [label="(8, 384, 12, 64) \n0 -> 0", style=solid];
"37 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/view_4" -> "39 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/NNCFLinear[out_lin]/linear_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"38 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/NNCFLinear[out_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "39 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/NNCFLinear[out_lin]/linear_0"  [label="(768, 768) \n0 -> 1", style=solid];
"39 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/MultiHeadSelfAttention[attention]/NNCFLinear[out_lin]/linear_0" -> "40 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/__add___0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"40 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/__add___0" -> "41 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/NNCFLayerNorm[sa_layer_norm]/layer_norm_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"41 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/NNCFLayerNorm[sa_layer_norm]/layer_norm_0" -> "43 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/FFN[ffn]/NNCFLinear[lin1]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"41 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/NNCFLayerNorm[sa_layer_norm]/layer_norm_0" -> "50 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/__add___1"  [label="(8, 384, 768) \n0 -> 1", style=solid];
"42 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/FFN[ffn]/NNCFLinear[lin1]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "44 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/FFN[ffn]/NNCFLinear[lin1]/linear_0"  [label="(3072, 768) \n0 -> 1", style=solid];
"43 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/FFN[ffn]/NNCFLinear[lin1]/AsymmetricQuantizer/asymmetric_quantize_0" -> "44 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/FFN[ffn]/NNCFLinear[lin1]/linear_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"44 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/FFN[ffn]/NNCFLinear[lin1]/linear_0" -> "45 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/FFN[ffn]/GELUActivation[activation]/gelu_0"  [label="(8, 384, 3072) \n0 -> 0", style=solid];
"45 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/FFN[ffn]/GELUActivation[activation]/gelu_0" -> "46 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/FFN[ffn]/GELUActivation[activation]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(8, 384, 3072) \n0 -> 0", style=solid];
"46 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/FFN[ffn]/GELUActivation[activation]/AsymmetricQuantizer/asymmetric_quantize_0" -> "48 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/FFN[ffn]/NNCFLinear[lin2]/linear_0"  [label="(8, 384, 3072) \n0 -> 0", style=solid];
"47 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/FFN[ffn]/NNCFLinear[lin2]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "48 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/FFN[ffn]/NNCFLinear[lin2]/linear_0"  [label="(768, 3072) \n0 -> 1", style=solid];
"48 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/FFN[ffn]/NNCFLinear[lin2]/linear_0" -> "49 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/FFN[ffn]/Dropout[dropout]/dropout_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"49 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/FFN[ffn]/Dropout[dropout]/dropout_0" -> "50 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/__add___1"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"50 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/__add___1" -> "51 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/NNCFLayerNorm[output_layer_norm]/layer_norm_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"51 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/NNCFLayerNorm[output_layer_norm]/layer_norm_0" -> "53 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"51 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/NNCFLayerNorm[output_layer_norm]/layer_norm_0" -> "58 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"51 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/NNCFLayerNorm[output_layer_norm]/layer_norm_0" -> "64 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"51 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[0]/NNCFLayerNorm[output_layer_norm]/layer_norm_0" -> "85 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/__add___0"  [label="(8, 384, 768) \n0 -> 1", style=solid];
"52 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "54 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/linear_0"  [label="(768, 768) \n0 -> 1", style=solid];
"53 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/AsymmetricQuantizer/asymmetric_quantize_0" -> "54 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/linear_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"54 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/linear_0" -> "55 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/view_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"55 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/view_0" -> "56 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/transpose_0"  [label="(8, 384, 12, 64) \n0 -> 0", style=solid];
"56 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/transpose_0" -> "68 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/__truediv___0"  [label="(8, 12, 384, 64) \n0 -> 0", style=solid];
"57 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "59 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/linear_0"  [label="(768, 768) \n0 -> 1", style=solid];
"58 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/AsymmetricQuantizer/asymmetric_quantize_0" -> "59 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/linear_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"59 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/linear_0" -> "60 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/SymmetricQuantizer/symmetric_quantize_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"60 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/SymmetricQuantizer/symmetric_quantize_0" -> "61 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/view_1"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"61 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/view_1" -> "62 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/transpose_1"  [label="(8, 384, 12, 64) \n0 -> 0", style=solid];
"62 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/transpose_1" -> "70 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/transpose_3"  [label="(8, 12, 384, 64) \n0 -> 0", style=solid];
"63 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "65 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/linear_0"  [label="(768, 768) \n0 -> 1", style=solid];
"64 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/AsymmetricQuantizer/asymmetric_quantize_0" -> "65 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/linear_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"65 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/linear_0" -> "66 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/view_2"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"66 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/view_2" -> "67 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/transpose_2"  [label="(8, 384, 12, 64) \n0 -> 0", style=solid];
"67 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/transpose_2" -> "78 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/matmul_1"  [label="(8, 12, 384, 64) \n0 -> 1", style=solid];
"68 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/__truediv___0" -> "69 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/SymmetricQuantizer/symmetric_quantize_0"  [label="(8, 12, 384, 64) \n0 -> 0", style=solid];
"69 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/SymmetricQuantizer/symmetric_quantize_0" -> "71 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/matmul_0"  [label="(8, 12, 384, 64) \n0 -> 0", style=solid];
"70 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/transpose_3" -> "71 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/matmul_0"  [label="(8, 12, 64, 384) \n0 -> 1", style=solid];
"71 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/matmul_0" -> "74 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/expand_as_0"  [label="(8, 12, 384, 384) \n0 -> 1", style=solid];
"71 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/matmul_0" -> "75 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/masked_fill_0"  [label="(8, 12, 384, 384) \n0 -> 0", style=solid];
"72 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/__eq___0" -> "73 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/view_3"  [label="(8, 384) \n0 -> 0", style=dashed];
"73 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/view_3" -> "74 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/expand_as_0"  [label="(8, 1, 1, 384) \n0 -> 0", style=dashed];
"74 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/expand_as_0" -> "75 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/masked_fill_0"  [label="(8, 12, 384, 384) \n0 -> 1", style=dashed];
"75 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/masked_fill_0" -> "76 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/softmax_0"  [label="(8, 12, 384, 384) \n0 -> 0", style=solid];
"76 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/softmax_0" -> "77 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/Dropout[dropout]/dropout_0"  [label="(8, 12, 384, 384) \n0 -> 0", style=solid];
"77 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/Dropout[dropout]/dropout_0" -> "78 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/matmul_1"  [label="(8, 12, 384, 384) \n0 -> 0", style=solid];
"78 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/matmul_1" -> "79 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(8, 12, 384, 64) \n0 -> 0", style=solid];
"79 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/AsymmetricQuantizer/asymmetric_quantize_0" -> "80 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/transpose_4"  [label="(8, 12, 384, 64) \n0 -> 0", style=solid];
"80 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/transpose_4" -> "81 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/contiguous_0"  [label="(8, 384, 12, 64) \n0 -> 0", style=solid];
"81 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/contiguous_0" -> "82 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/view_4"  [label="(8, 384, 12, 64) \n0 -> 0", style=solid];
"82 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/view_4" -> "84 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/NNCFLinear[out_lin]/linear_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"83 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/NNCFLinear[out_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "84 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/NNCFLinear[out_lin]/linear_0"  [label="(768, 768) \n0 -> 1", style=solid];
"84 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/MultiHeadSelfAttention[attention]/NNCFLinear[out_lin]/linear_0" -> "85 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/__add___0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"85 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/__add___0" -> "86 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/NNCFLayerNorm[sa_layer_norm]/layer_norm_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"86 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/NNCFLayerNorm[sa_layer_norm]/layer_norm_0" -> "88 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/FFN[ffn]/NNCFLinear[lin1]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"86 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/NNCFLayerNorm[sa_layer_norm]/layer_norm_0" -> "95 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/__add___1"  [label="(8, 384, 768) \n0 -> 1", style=solid];
"87 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/FFN[ffn]/NNCFLinear[lin1]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "89 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/FFN[ffn]/NNCFLinear[lin1]/linear_0"  [label="(3072, 768) \n0 -> 1", style=solid];
"88 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/FFN[ffn]/NNCFLinear[lin1]/AsymmetricQuantizer/asymmetric_quantize_0" -> "89 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/FFN[ffn]/NNCFLinear[lin1]/linear_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"89 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/FFN[ffn]/NNCFLinear[lin1]/linear_0" -> "90 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/FFN[ffn]/GELUActivation[activation]/gelu_0"  [label="(8, 384, 3072) \n0 -> 0", style=solid];
"90 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/FFN[ffn]/GELUActivation[activation]/gelu_0" -> "91 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/FFN[ffn]/GELUActivation[activation]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(8, 384, 3072) \n0 -> 0", style=solid];
"91 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/FFN[ffn]/GELUActivation[activation]/AsymmetricQuantizer/asymmetric_quantize_0" -> "93 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/FFN[ffn]/NNCFLinear[lin2]/linear_0"  [label="(8, 384, 3072) \n0 -> 0", style=solid];
"92 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/FFN[ffn]/NNCFLinear[lin2]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "93 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/FFN[ffn]/NNCFLinear[lin2]/linear_0"  [label="(768, 3072) \n0 -> 1", style=solid];
"93 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/FFN[ffn]/NNCFLinear[lin2]/linear_0" -> "94 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/FFN[ffn]/Dropout[dropout]/dropout_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"94 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/FFN[ffn]/Dropout[dropout]/dropout_0" -> "95 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/__add___1"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"95 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/__add___1" -> "96 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/NNCFLayerNorm[output_layer_norm]/layer_norm_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"96 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/NNCFLayerNorm[output_layer_norm]/layer_norm_0" -> "98 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"96 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/NNCFLayerNorm[output_layer_norm]/layer_norm_0" -> "103 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"96 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/NNCFLayerNorm[output_layer_norm]/layer_norm_0" -> "109 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"96 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[1]/NNCFLayerNorm[output_layer_norm]/layer_norm_0" -> "130 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/__add___0"  [label="(8, 384, 768) \n0 -> 1", style=solid];
"97 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "99 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/linear_0"  [label="(768, 768) \n0 -> 1", style=solid];
"98 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/AsymmetricQuantizer/asymmetric_quantize_0" -> "99 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/linear_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"99 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/linear_0" -> "100 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/view_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"100 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/view_0" -> "101 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/transpose_0"  [label="(8, 384, 12, 64) \n0 -> 0", style=solid];
"101 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/transpose_0" -> "113 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/__truediv___0"  [label="(8, 12, 384, 64) \n0 -> 0", style=solid];
"102 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "104 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/linear_0"  [label="(768, 768) \n0 -> 1", style=solid];
"103 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/AsymmetricQuantizer/asymmetric_quantize_0" -> "104 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/linear_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"104 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/linear_0" -> "105 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/SymmetricQuantizer/symmetric_quantize_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"105 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/SymmetricQuantizer/symmetric_quantize_0" -> "106 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/view_1"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"106 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/view_1" -> "107 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/transpose_1"  [label="(8, 384, 12, 64) \n0 -> 0", style=solid];
"107 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/transpose_1" -> "115 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/transpose_3"  [label="(8, 12, 384, 64) \n0 -> 0", style=solid];
"108 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "110 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/linear_0"  [label="(768, 768) \n0 -> 1", style=solid];
"109 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/AsymmetricQuantizer/asymmetric_quantize_0" -> "110 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/linear_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"110 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/linear_0" -> "111 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/view_2"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"111 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/view_2" -> "112 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/transpose_2"  [label="(8, 384, 12, 64) \n0 -> 0", style=solid];
"112 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/transpose_2" -> "123 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/matmul_1"  [label="(8, 12, 384, 64) \n0 -> 1", style=solid];
"113 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/__truediv___0" -> "114 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/SymmetricQuantizer/symmetric_quantize_0"  [label="(8, 12, 384, 64) \n0 -> 0", style=solid];
"114 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/SymmetricQuantizer/symmetric_quantize_0" -> "116 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/matmul_0"  [label="(8, 12, 384, 64) \n0 -> 0", style=solid];
"115 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/transpose_3" -> "116 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/matmul_0"  [label="(8, 12, 64, 384) \n0 -> 1", style=solid];
"116 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/matmul_0" -> "119 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/expand_as_0"  [label="(8, 12, 384, 384) \n0 -> 1", style=solid];
"116 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/matmul_0" -> "120 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/masked_fill_0"  [label="(8, 12, 384, 384) \n0 -> 0", style=solid];
"117 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/__eq___0" -> "118 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/view_3"  [label="(8, 384) \n0 -> 0", style=dashed];
"118 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/view_3" -> "119 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/expand_as_0"  [label="(8, 1, 1, 384) \n0 -> 0", style=dashed];
"119 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/expand_as_0" -> "120 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/masked_fill_0"  [label="(8, 12, 384, 384) \n0 -> 1", style=dashed];
"120 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/masked_fill_0" -> "121 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/softmax_0"  [label="(8, 12, 384, 384) \n0 -> 0", style=solid];
"121 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/softmax_0" -> "122 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/Dropout[dropout]/dropout_0"  [label="(8, 12, 384, 384) \n0 -> 0", style=solid];
"122 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/Dropout[dropout]/dropout_0" -> "123 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/matmul_1"  [label="(8, 12, 384, 384) \n0 -> 0", style=solid];
"123 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/matmul_1" -> "124 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(8, 12, 384, 64) \n0 -> 0", style=solid];
"124 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/AsymmetricQuantizer/asymmetric_quantize_0" -> "125 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/transpose_4"  [label="(8, 12, 384, 64) \n0 -> 0", style=solid];
"125 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/transpose_4" -> "126 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/contiguous_0"  [label="(8, 384, 12, 64) \n0 -> 0", style=solid];
"126 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/contiguous_0" -> "127 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/view_4"  [label="(8, 384, 12, 64) \n0 -> 0", style=solid];
"127 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/view_4" -> "129 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/NNCFLinear[out_lin]/linear_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"128 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/NNCFLinear[out_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "129 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/NNCFLinear[out_lin]/linear_0"  [label="(768, 768) \n0 -> 1", style=solid];
"129 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/MultiHeadSelfAttention[attention]/NNCFLinear[out_lin]/linear_0" -> "130 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/__add___0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"130 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/__add___0" -> "131 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/NNCFLayerNorm[sa_layer_norm]/layer_norm_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"131 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/NNCFLayerNorm[sa_layer_norm]/layer_norm_0" -> "133 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/FFN[ffn]/NNCFLinear[lin1]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"131 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/NNCFLayerNorm[sa_layer_norm]/layer_norm_0" -> "140 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/__add___1"  [label="(8, 384, 768) \n0 -> 1", style=solid];
"132 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/FFN[ffn]/NNCFLinear[lin1]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "134 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/FFN[ffn]/NNCFLinear[lin1]/linear_0"  [label="(3072, 768) \n0 -> 1", style=solid];
"133 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/FFN[ffn]/NNCFLinear[lin1]/AsymmetricQuantizer/asymmetric_quantize_0" -> "134 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/FFN[ffn]/NNCFLinear[lin1]/linear_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"134 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/FFN[ffn]/NNCFLinear[lin1]/linear_0" -> "135 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/FFN[ffn]/GELUActivation[activation]/gelu_0"  [label="(8, 384, 3072) \n0 -> 0", style=solid];
"135 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/FFN[ffn]/GELUActivation[activation]/gelu_0" -> "136 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/FFN[ffn]/GELUActivation[activation]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(8, 384, 3072) \n0 -> 0", style=solid];
"136 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/FFN[ffn]/GELUActivation[activation]/AsymmetricQuantizer/asymmetric_quantize_0" -> "138 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/FFN[ffn]/NNCFLinear[lin2]/linear_0"  [label="(8, 384, 3072) \n0 -> 0", style=solid];
"137 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/FFN[ffn]/NNCFLinear[lin2]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "138 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/FFN[ffn]/NNCFLinear[lin2]/linear_0"  [label="(768, 3072) \n0 -> 1", style=solid];
"138 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/FFN[ffn]/NNCFLinear[lin2]/linear_0" -> "139 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/FFN[ffn]/Dropout[dropout]/dropout_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"139 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/FFN[ffn]/Dropout[dropout]/dropout_0" -> "140 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/__add___1"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"140 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/__add___1" -> "141 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/NNCFLayerNorm[output_layer_norm]/layer_norm_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"141 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/NNCFLayerNorm[output_layer_norm]/layer_norm_0" -> "143 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"141 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/NNCFLayerNorm[output_layer_norm]/layer_norm_0" -> "148 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"141 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/NNCFLayerNorm[output_layer_norm]/layer_norm_0" -> "154 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"141 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[2]/NNCFLayerNorm[output_layer_norm]/layer_norm_0" -> "175 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/__add___0"  [label="(8, 384, 768) \n0 -> 1", style=solid];
"142 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "144 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/linear_0"  [label="(768, 768) \n0 -> 1", style=solid];
"143 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/AsymmetricQuantizer/asymmetric_quantize_0" -> "144 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/linear_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"144 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/linear_0" -> "145 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/view_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"145 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/view_0" -> "146 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/transpose_0"  [label="(8, 384, 12, 64) \n0 -> 0", style=solid];
"146 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/transpose_0" -> "158 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/__truediv___0"  [label="(8, 12, 384, 64) \n0 -> 0", style=solid];
"147 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "149 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/linear_0"  [label="(768, 768) \n0 -> 1", style=solid];
"148 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/AsymmetricQuantizer/asymmetric_quantize_0" -> "149 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/linear_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"149 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/linear_0" -> "150 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/SymmetricQuantizer/symmetric_quantize_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"150 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/SymmetricQuantizer/symmetric_quantize_0" -> "151 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/view_1"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"151 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/view_1" -> "152 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/transpose_1"  [label="(8, 384, 12, 64) \n0 -> 0", style=solid];
"152 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/transpose_1" -> "160 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/transpose_3"  [label="(8, 12, 384, 64) \n0 -> 0", style=solid];
"153 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "155 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/linear_0"  [label="(768, 768) \n0 -> 1", style=solid];
"154 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/AsymmetricQuantizer/asymmetric_quantize_0" -> "155 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/linear_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"155 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/linear_0" -> "156 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/view_2"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"156 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/view_2" -> "157 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/transpose_2"  [label="(8, 384, 12, 64) \n0 -> 0", style=solid];
"157 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/transpose_2" -> "168 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/matmul_1"  [label="(8, 12, 384, 64) \n0 -> 1", style=solid];
"158 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/__truediv___0" -> "159 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/SymmetricQuantizer/symmetric_quantize_0"  [label="(8, 12, 384, 64) \n0 -> 0", style=solid];
"159 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/SymmetricQuantizer/symmetric_quantize_0" -> "161 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/matmul_0"  [label="(8, 12, 384, 64) \n0 -> 0", style=solid];
"160 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/transpose_3" -> "161 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/matmul_0"  [label="(8, 12, 64, 384) \n0 -> 1", style=solid];
"161 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/matmul_0" -> "164 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/expand_as_0"  [label="(8, 12, 384, 384) \n0 -> 1", style=solid];
"161 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/matmul_0" -> "165 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/masked_fill_0"  [label="(8, 12, 384, 384) \n0 -> 0", style=solid];
"162 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/__eq___0" -> "163 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/view_3"  [label="(8, 384) \n0 -> 0", style=dashed];
"163 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/view_3" -> "164 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/expand_as_0"  [label="(8, 1, 1, 384) \n0 -> 0", style=dashed];
"164 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/expand_as_0" -> "165 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/masked_fill_0"  [label="(8, 12, 384, 384) \n0 -> 1", style=dashed];
"165 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/masked_fill_0" -> "166 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/softmax_0"  [label="(8, 12, 384, 384) \n0 -> 0", style=solid];
"166 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/softmax_0" -> "167 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/Dropout[dropout]/dropout_0"  [label="(8, 12, 384, 384) \n0 -> 0", style=solid];
"167 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/Dropout[dropout]/dropout_0" -> "168 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/matmul_1"  [label="(8, 12, 384, 384) \n0 -> 0", style=solid];
"168 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/matmul_1" -> "169 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(8, 12, 384, 64) \n0 -> 0", style=solid];
"169 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/AsymmetricQuantizer/asymmetric_quantize_0" -> "170 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/transpose_4"  [label="(8, 12, 384, 64) \n0 -> 0", style=solid];
"170 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/transpose_4" -> "171 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/contiguous_0"  [label="(8, 384, 12, 64) \n0 -> 0", style=solid];
"171 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/contiguous_0" -> "172 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/view_4"  [label="(8, 384, 12, 64) \n0 -> 0", style=solid];
"172 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/view_4" -> "174 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/NNCFLinear[out_lin]/linear_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"173 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/NNCFLinear[out_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "174 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/NNCFLinear[out_lin]/linear_0"  [label="(768, 768) \n0 -> 1", style=solid];
"174 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/MultiHeadSelfAttention[attention]/NNCFLinear[out_lin]/linear_0" -> "175 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/__add___0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"175 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/__add___0" -> "176 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/NNCFLayerNorm[sa_layer_norm]/layer_norm_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"176 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/NNCFLayerNorm[sa_layer_norm]/layer_norm_0" -> "178 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/FFN[ffn]/NNCFLinear[lin1]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"176 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/NNCFLayerNorm[sa_layer_norm]/layer_norm_0" -> "185 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/__add___1"  [label="(8, 384, 768) \n0 -> 1", style=solid];
"177 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/FFN[ffn]/NNCFLinear[lin1]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "179 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/FFN[ffn]/NNCFLinear[lin1]/linear_0"  [label="(3072, 768) \n0 -> 1", style=solid];
"178 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/FFN[ffn]/NNCFLinear[lin1]/AsymmetricQuantizer/asymmetric_quantize_0" -> "179 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/FFN[ffn]/NNCFLinear[lin1]/linear_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"179 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/FFN[ffn]/NNCFLinear[lin1]/linear_0" -> "180 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/FFN[ffn]/GELUActivation[activation]/gelu_0"  [label="(8, 384, 3072) \n0 -> 0", style=solid];
"180 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/FFN[ffn]/GELUActivation[activation]/gelu_0" -> "181 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/FFN[ffn]/GELUActivation[activation]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(8, 384, 3072) \n0 -> 0", style=solid];
"181 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/FFN[ffn]/GELUActivation[activation]/AsymmetricQuantizer/asymmetric_quantize_0" -> "183 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/FFN[ffn]/NNCFLinear[lin2]/linear_0"  [label="(8, 384, 3072) \n0 -> 0", style=solid];
"182 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/FFN[ffn]/NNCFLinear[lin2]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "183 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/FFN[ffn]/NNCFLinear[lin2]/linear_0"  [label="(768, 3072) \n0 -> 1", style=solid];
"183 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/FFN[ffn]/NNCFLinear[lin2]/linear_0" -> "184 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/FFN[ffn]/Dropout[dropout]/dropout_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"184 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/FFN[ffn]/Dropout[dropout]/dropout_0" -> "185 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/__add___1"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"185 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/__add___1" -> "186 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/NNCFLayerNorm[output_layer_norm]/layer_norm_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"186 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/NNCFLayerNorm[output_layer_norm]/layer_norm_0" -> "188 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"186 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/NNCFLayerNorm[output_layer_norm]/layer_norm_0" -> "193 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"186 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/NNCFLayerNorm[output_layer_norm]/layer_norm_0" -> "199 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"186 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[3]/NNCFLayerNorm[output_layer_norm]/layer_norm_0" -> "220 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/__add___0"  [label="(8, 384, 768) \n0 -> 1", style=solid];
"187 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "189 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/linear_0"  [label="(768, 768) \n0 -> 1", style=solid];
"188 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/AsymmetricQuantizer/asymmetric_quantize_0" -> "189 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/linear_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"189 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/linear_0" -> "190 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/view_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"190 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/view_0" -> "191 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/transpose_0"  [label="(8, 384, 12, 64) \n0 -> 0", style=solid];
"191 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/transpose_0" -> "203 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/__truediv___0"  [label="(8, 12, 384, 64) \n0 -> 0", style=solid];
"192 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "194 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/linear_0"  [label="(768, 768) \n0 -> 1", style=solid];
"193 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/AsymmetricQuantizer/asymmetric_quantize_0" -> "194 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/linear_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"194 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/linear_0" -> "195 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/SymmetricQuantizer/symmetric_quantize_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"195 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/SymmetricQuantizer/symmetric_quantize_0" -> "196 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/view_1"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"196 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/view_1" -> "197 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/transpose_1"  [label="(8, 384, 12, 64) \n0 -> 0", style=solid];
"197 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/transpose_1" -> "205 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/transpose_3"  [label="(8, 12, 384, 64) \n0 -> 0", style=solid];
"198 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "200 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/linear_0"  [label="(768, 768) \n0 -> 1", style=solid];
"199 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/AsymmetricQuantizer/asymmetric_quantize_0" -> "200 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/linear_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"200 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/linear_0" -> "201 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/view_2"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"201 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/view_2" -> "202 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/transpose_2"  [label="(8, 384, 12, 64) \n0 -> 0", style=solid];
"202 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/transpose_2" -> "213 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/matmul_1"  [label="(8, 12, 384, 64) \n0 -> 1", style=solid];
"203 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/__truediv___0" -> "204 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/SymmetricQuantizer/symmetric_quantize_0"  [label="(8, 12, 384, 64) \n0 -> 0", style=solid];
"204 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/SymmetricQuantizer/symmetric_quantize_0" -> "206 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/matmul_0"  [label="(8, 12, 384, 64) \n0 -> 0", style=solid];
"205 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/transpose_3" -> "206 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/matmul_0"  [label="(8, 12, 64, 384) \n0 -> 1", style=solid];
"206 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/matmul_0" -> "209 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/expand_as_0"  [label="(8, 12, 384, 384) \n0 -> 1", style=solid];
"206 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/matmul_0" -> "210 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/masked_fill_0"  [label="(8, 12, 384, 384) \n0 -> 0", style=solid];
"207 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/__eq___0" -> "208 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/view_3"  [label="(8, 384) \n0 -> 0", style=dashed];
"208 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/view_3" -> "209 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/expand_as_0"  [label="(8, 1, 1, 384) \n0 -> 0", style=dashed];
"209 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/expand_as_0" -> "210 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/masked_fill_0"  [label="(8, 12, 384, 384) \n0 -> 1", style=dashed];
"210 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/masked_fill_0" -> "211 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/softmax_0"  [label="(8, 12, 384, 384) \n0 -> 0", style=solid];
"211 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/softmax_0" -> "212 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/Dropout[dropout]/dropout_0"  [label="(8, 12, 384, 384) \n0 -> 0", style=solid];
"212 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/Dropout[dropout]/dropout_0" -> "213 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/matmul_1"  [label="(8, 12, 384, 384) \n0 -> 0", style=solid];
"213 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/matmul_1" -> "214 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(8, 12, 384, 64) \n0 -> 0", style=solid];
"214 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/AsymmetricQuantizer/asymmetric_quantize_0" -> "215 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/transpose_4"  [label="(8, 12, 384, 64) \n0 -> 0", style=solid];
"215 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/transpose_4" -> "216 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/contiguous_0"  [label="(8, 384, 12, 64) \n0 -> 0", style=solid];
"216 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/contiguous_0" -> "217 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/view_4"  [label="(8, 384, 12, 64) \n0 -> 0", style=solid];
"217 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/view_4" -> "219 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/NNCFLinear[out_lin]/linear_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"218 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/NNCFLinear[out_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "219 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/NNCFLinear[out_lin]/linear_0"  [label="(768, 768) \n0 -> 1", style=solid];
"219 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/MultiHeadSelfAttention[attention]/NNCFLinear[out_lin]/linear_0" -> "220 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/__add___0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"220 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/__add___0" -> "221 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/NNCFLayerNorm[sa_layer_norm]/layer_norm_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"221 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/NNCFLayerNorm[sa_layer_norm]/layer_norm_0" -> "223 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/FFN[ffn]/NNCFLinear[lin1]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"221 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/NNCFLayerNorm[sa_layer_norm]/layer_norm_0" -> "230 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/__add___1"  [label="(8, 384, 768) \n0 -> 1", style=solid];
"222 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/FFN[ffn]/NNCFLinear[lin1]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "224 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/FFN[ffn]/NNCFLinear[lin1]/linear_0"  [label="(3072, 768) \n0 -> 1", style=solid];
"223 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/FFN[ffn]/NNCFLinear[lin1]/AsymmetricQuantizer/asymmetric_quantize_0" -> "224 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/FFN[ffn]/NNCFLinear[lin1]/linear_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"224 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/FFN[ffn]/NNCFLinear[lin1]/linear_0" -> "225 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/FFN[ffn]/GELUActivation[activation]/gelu_0"  [label="(8, 384, 3072) \n0 -> 0", style=solid];
"225 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/FFN[ffn]/GELUActivation[activation]/gelu_0" -> "226 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/FFN[ffn]/GELUActivation[activation]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(8, 384, 3072) \n0 -> 0", style=solid];
"226 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/FFN[ffn]/GELUActivation[activation]/AsymmetricQuantizer/asymmetric_quantize_0" -> "228 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/FFN[ffn]/NNCFLinear[lin2]/linear_0"  [label="(8, 384, 3072) \n0 -> 0", style=solid];
"227 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/FFN[ffn]/NNCFLinear[lin2]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "228 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/FFN[ffn]/NNCFLinear[lin2]/linear_0"  [label="(768, 3072) \n0 -> 1", style=solid];
"228 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/FFN[ffn]/NNCFLinear[lin2]/linear_0" -> "229 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/FFN[ffn]/Dropout[dropout]/dropout_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"229 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/FFN[ffn]/Dropout[dropout]/dropout_0" -> "230 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/__add___1"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"230 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/__add___1" -> "231 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/NNCFLayerNorm[output_layer_norm]/layer_norm_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"231 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/NNCFLayerNorm[output_layer_norm]/layer_norm_0" -> "233 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"231 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/NNCFLayerNorm[output_layer_norm]/layer_norm_0" -> "238 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"231 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/NNCFLayerNorm[output_layer_norm]/layer_norm_0" -> "244 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"231 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[4]/NNCFLayerNorm[output_layer_norm]/layer_norm_0" -> "265 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/__add___0"  [label="(8, 384, 768) \n0 -> 1", style=solid];
"232 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "234 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/linear_0"  [label="(768, 768) \n0 -> 1", style=solid];
"233 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/AsymmetricQuantizer/asymmetric_quantize_0" -> "234 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/linear_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"234 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/NNCFLinear[q_lin]/linear_0" -> "235 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/view_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"235 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/view_0" -> "236 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/transpose_0"  [label="(8, 384, 12, 64) \n0 -> 0", style=solid];
"236 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/transpose_0" -> "248 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/__truediv___0"  [label="(8, 12, 384, 64) \n0 -> 0", style=solid];
"237 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "239 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/linear_0"  [label="(768, 768) \n0 -> 1", style=solid];
"238 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/AsymmetricQuantizer/asymmetric_quantize_0" -> "239 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/linear_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"239 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/linear_0" -> "240 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/SymmetricQuantizer/symmetric_quantize_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"240 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/NNCFLinear[k_lin]/SymmetricQuantizer/symmetric_quantize_0" -> "241 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/view_1"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"241 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/view_1" -> "242 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/transpose_1"  [label="(8, 384, 12, 64) \n0 -> 0", style=solid];
"242 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/transpose_1" -> "250 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/transpose_3"  [label="(8, 12, 384, 64) \n0 -> 0", style=solid];
"243 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "245 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/linear_0"  [label="(768, 768) \n0 -> 1", style=solid];
"244 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/AsymmetricQuantizer/asymmetric_quantize_0" -> "245 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/linear_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"245 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/NNCFLinear[v_lin]/linear_0" -> "246 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/view_2"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"246 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/view_2" -> "247 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/transpose_2"  [label="(8, 384, 12, 64) \n0 -> 0", style=solid];
"247 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/transpose_2" -> "258 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/matmul_1"  [label="(8, 12, 384, 64) \n0 -> 1", style=solid];
"248 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/__truediv___0" -> "249 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/SymmetricQuantizer/symmetric_quantize_0"  [label="(8, 12, 384, 64) \n0 -> 0", style=solid];
"249 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/SymmetricQuantizer/symmetric_quantize_0" -> "251 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/matmul_0"  [label="(8, 12, 384, 64) \n0 -> 0", style=solid];
"250 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/transpose_3" -> "251 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/matmul_0"  [label="(8, 12, 64, 384) \n0 -> 1", style=solid];
"251 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/matmul_0" -> "254 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/expand_as_0"  [label="(8, 12, 384, 384) \n0 -> 1", style=solid];
"251 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/matmul_0" -> "255 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/masked_fill_0"  [label="(8, 12, 384, 384) \n0 -> 0", style=solid];
"252 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/__eq___0" -> "253 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/view_3"  [label="(8, 384) \n0 -> 0", style=dashed];
"253 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/view_3" -> "254 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/expand_as_0"  [label="(8, 1, 1, 384) \n0 -> 0", style=dashed];
"254 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/expand_as_0" -> "255 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/masked_fill_0"  [label="(8, 12, 384, 384) \n0 -> 1", style=dashed];
"255 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/masked_fill_0" -> "256 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/softmax_0"  [label="(8, 12, 384, 384) \n0 -> 0", style=solid];
"256 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/softmax_0" -> "257 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/Dropout[dropout]/dropout_0"  [label="(8, 12, 384, 384) \n0 -> 0", style=solid];
"257 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/Dropout[dropout]/dropout_0" -> "258 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/matmul_1"  [label="(8, 12, 384, 384) \n0 -> 0", style=solid];
"258 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/matmul_1" -> "259 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(8, 12, 384, 64) \n0 -> 0", style=solid];
"259 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/AsymmetricQuantizer/asymmetric_quantize_0" -> "260 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/transpose_4"  [label="(8, 12, 384, 64) \n0 -> 0", style=solid];
"260 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/transpose_4" -> "261 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/contiguous_0"  [label="(8, 384, 12, 64) \n0 -> 0", style=solid];
"261 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/contiguous_0" -> "262 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/view_4"  [label="(8, 384, 12, 64) \n0 -> 0", style=solid];
"262 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/view_4" -> "264 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/NNCFLinear[out_lin]/linear_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"263 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/NNCFLinear[out_lin]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "264 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/NNCFLinear[out_lin]/linear_0"  [label="(768, 768) \n0 -> 1", style=solid];
"264 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/MultiHeadSelfAttention[attention]/NNCFLinear[out_lin]/linear_0" -> "265 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/__add___0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"265 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/__add___0" -> "266 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/NNCFLayerNorm[sa_layer_norm]/layer_norm_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"266 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/NNCFLayerNorm[sa_layer_norm]/layer_norm_0" -> "268 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/FFN[ffn]/NNCFLinear[lin1]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"266 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/NNCFLayerNorm[sa_layer_norm]/layer_norm_0" -> "275 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/__add___1"  [label="(8, 384, 768) \n0 -> 1", style=solid];
"267 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/FFN[ffn]/NNCFLinear[lin1]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "269 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/FFN[ffn]/NNCFLinear[lin1]/linear_0"  [label="(3072, 768) \n0 -> 1", style=solid];
"268 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/FFN[ffn]/NNCFLinear[lin1]/AsymmetricQuantizer/asymmetric_quantize_0" -> "269 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/FFN[ffn]/NNCFLinear[lin1]/linear_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"269 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/FFN[ffn]/NNCFLinear[lin1]/linear_0" -> "270 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/FFN[ffn]/GELUActivation[activation]/gelu_0"  [label="(8, 384, 3072) \n0 -> 0", style=solid];
"270 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/FFN[ffn]/GELUActivation[activation]/gelu_0" -> "271 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/FFN[ffn]/GELUActivation[activation]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(8, 384, 3072) \n0 -> 0", style=solid];
"271 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/FFN[ffn]/GELUActivation[activation]/AsymmetricQuantizer/asymmetric_quantize_0" -> "273 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/FFN[ffn]/NNCFLinear[lin2]/linear_0"  [label="(8, 384, 3072) \n0 -> 0", style=solid];
"272 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/FFN[ffn]/NNCFLinear[lin2]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "273 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/FFN[ffn]/NNCFLinear[lin2]/linear_0"  [label="(768, 3072) \n0 -> 1", style=solid];
"273 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/FFN[ffn]/NNCFLinear[lin2]/linear_0" -> "274 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/FFN[ffn]/Dropout[dropout]/dropout_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"274 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/FFN[ffn]/Dropout[dropout]/dropout_0" -> "275 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/__add___1"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"275 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/__add___1" -> "276 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/NNCFLayerNorm[output_layer_norm]/layer_norm_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"276 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/NNCFLayerNorm[output_layer_norm]/layer_norm_0" -> "277 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/NNCFLayerNorm[output_layer_norm]/AsymmetricQuantizer/asymmetric_quantize_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"277 DistilBertForQuestionAnswering/DistilBertModel[distilbert]/Transformer[transformer]/ModuleList[layer]/TransformerBlock[5]/NNCFLayerNorm[output_layer_norm]/AsymmetricQuantizer/asymmetric_quantize_0" -> "278 DistilBertForQuestionAnswering/Dropout[dropout]/dropout_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"278 DistilBertForQuestionAnswering/Dropout[dropout]/dropout_0" -> "280 DistilBertForQuestionAnswering/NNCFLinear[qa_outputs]/linear_0"  [label="(8, 384, 768) \n0 -> 0", style=solid];
"279 DistilBertForQuestionAnswering/NNCFLinear[qa_outputs]/ModuleDict[pre_ops]/UpdateWeight[0]/SymmetricQuantizer[op]/symmetric_quantize_0" -> "280 DistilBertForQuestionAnswering/NNCFLinear[qa_outputs]/linear_0"  [label="(2, 768) \n0 -> 1", style=solid];
"280 DistilBertForQuestionAnswering/NNCFLinear[qa_outputs]/linear_0" -> "281 DistilBertForQuestionAnswering/split_0"  [label="(8, 384, 2) \n0 -> 0", style=solid];
"281 DistilBertForQuestionAnswering/split_0" -> "282 DistilBertForQuestionAnswering/squeeze_0"  [label="(8, 384, 1) \n0 -> 0", style=solid];
"281 DistilBertForQuestionAnswering/split_0" -> "284 DistilBertForQuestionAnswering/squeeze_1"  [label="(8, 384, 1) \n1 -> 0", style=solid];
"282 DistilBertForQuestionAnswering/squeeze_0" -> "283 DistilBertForQuestionAnswering/contiguous_0"  [label="(8, 384) \n0 -> 0", style=solid];
"283 DistilBertForQuestionAnswering/contiguous_0" -> "286 /nncf_model_output_0"  [label="(8, 384) \n0 -> 0", style=solid];
"284 DistilBertForQuestionAnswering/squeeze_1" -> "285 DistilBertForQuestionAnswering/contiguous_1"  [label="(8, 384) \n0 -> 0", style=solid];
"285 DistilBertForQuestionAnswering/contiguous_1" -> "287 /nncf_model_output_1"  [label="(8, 384) \n0 -> 0", style=solid];
}
